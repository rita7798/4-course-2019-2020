{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статьи с сайта https://mos.ru  \n",
    "ключевые слова также со страниц со статьями (по 4 в каждой) + одно мое ключевое слово, всего для каждого текста по 5 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/margaritaberseneva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import RAKE\n",
    "import re\n",
    "import pandas as pd\n",
    "from gensim.summarization import keywords as kw\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from statistics import mean \n",
    "from textdistance import levenshtein\n",
    "\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('russian')\n",
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe = 'туризм #ярмарка #ресторан #кафе #гид'\n",
    "train = 'мцд #тариф #билет #турникет #проезд'\n",
    "cable_car = 'праздник #акция #лужники #канатная дорога #день рождения'\n",
    "court = 'Сергей Собянин #апелляционный суд #кассационный суд #судебный акт #суд'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сбор текстов и ключевых слов\n",
    "\n",
    "txt = {}\n",
    "keys = {}\n",
    "\n",
    "with open('1.txt', 'r', encoding='utf-8') as f:\n",
    "            t = f.read()\n",
    "            txt ['cafe'] = t\n",
    "            keys ['cafe'] = cafe\n",
    "            \n",
    "with open('2.txt', 'r', encoding='utf-8') as f:\n",
    "            t = f.read()\n",
    "            txt ['train'] = t\n",
    "            keys ['train'] = train\n",
    "\n",
    "with open('3.txt', 'r', encoding='utf-8') as f:\n",
    "            t = f.read()\n",
    "            txt ['cable_car'] = t\n",
    "            keys ['cable_car'] = cable_car\n",
    "\n",
    "with open('4.txt', 'r', encoding='utf-8') as f:\n",
    "            t = f.read()\n",
    "            txt ['court'] = t\n",
    "            keys ['court'] = court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лемматизация текстов\n",
    "\n",
    "new_txt = {}\n",
    "\n",
    "for t in txt.keys():\n",
    "    text = txt[t]\n",
    "    text = re.sub(r'\\n', r' ', text)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    new = ''\n",
    "    for w in text:\n",
    "        l = morph.parse(w)[0].normal_form + ' '\n",
    "        new += l\n",
    "    new_txt[t] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "туризм  —  1\n",
      "ярмарка  —  0\n",
      "ресторан  —  5\n",
      "кафе  —  0\n",
      "гид  —  3\n",
      "\n",
      "\n",
      "train\n",
      "мцд  —  17\n",
      "тариф  —  6\n",
      "билет  —  1\n",
      "турникет  —  3\n",
      "проезд  —  6\n",
      "\n",
      "\n",
      "cable_car\n",
      "праздник  —  0\n",
      "акция  —  0\n",
      "лужники  —  4\n",
      "канатная дорога  —  0\n",
      "день рождения  —  0\n",
      "\n",
      "\n",
      "court\n",
      "Сергей Собянин  —  0\n",
      "апелляционный суд  —  3\n",
      "кассационный суд  —  4\n",
      "судебный акт  —  4\n",
      "суд  —  25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#пробуем пройтись с ключевыми словами по лемматизированным текстам \n",
    "\n",
    "for key, value in keys.items():\n",
    "    v = value.split(' #')\n",
    "    for w, text in new_txt.items():\n",
    "        if w == key:\n",
    "            print(key)\n",
    "            for word in v:\n",
    "                c = new_txt[w].count(word)\n",
    "                print(word, ' — ', c)\n",
    "            print('\\n')\n",
    "            keys[key] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более-менее что-то вырисовывается. Ключевые слова в большинстве своем встречаются в текстах. Субъективно лучше всего с этим обстоят дела у текста про поезда, затем у текстов про суды и кафе. Совсем все плохо у текста про канатную дорогу, но все равно есть хоть что-то."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "('редакция гид', 4.0)\n",
      "('китайский язык', 4.0)\n",
      "('поддержка комитет', 4.0)\n",
      "('иностранный язык', 4.0)\n",
      "('сборник попасть', 3.5)\n",
      "('сборник', 1.5)\n",
      "('путеводитель', 1.0)\n",
      "('русский', 1.0)\n",
      "('английский', 1.0)\n",
      "('войти', 1.0)\n",
      "('сервис', 1.0)\n",
      "\n",
      "\n",
      "train\n",
      "('тройка стрелка', 4.0)\n",
      "('это сообщить', 4.0)\n",
      "('карта движение', 4.0)\n",
      "('первое диаметр', 4.0)\n",
      "('станция марк', 4.0)\n",
      "('который поездка', 4.0)\n",
      "('это пересадка', 4.0)\n",
      "('оплата проезд', 3.75)\n",
      "('остафьево проезд', 3.75)\n",
      "('проезд оплачиваться', 3.75)\n",
      "('сутки ожидаться', 3.5)\n",
      "('год тариф', 3.5)\n",
      "('проезд', 1.75)\n",
      "('сутки', 1.5)\n",
      "('год', 1.5)\n",
      "('сегодня', 1.0)\n",
      "('валидатор', 1.0)\n",
      "('понедельник', 1.0)\n",
      "('25 ноябрь', 1.0)\n",
      "('мцд 1', 1.0)\n",
      "('миллион', 1.0)\n",
      "('совершить', 1.0)\n",
      "('второе', 1.0)\n",
      "('пассажиропоток', 1.0)\n",
      "('связь', 1.0)\n",
      "('мцд', 1.0)\n",
      "('сетунь', 1.0)\n",
      "('мцд 2', 1.0)\n",
      "('метро', 1.0)\n",
      "('предел', 1.0)\n",
      "('мцк', 1.0)\n",
      "('10', 0)\n",
      "('11', 0)\n",
      "\n",
      "\n",
      "cable_car\n",
      "('канатный дорога', 4.0)\n",
      "('весь желающий', 4.0)\n",
      "('воробьев гора', 4.0)\n",
      "('удобный возможность', 4.0)\n",
      "('пять минута', 4.0)\n",
      "('велосипед лыжа', 4.0)\n",
      "('инвалидный коляска', 4.0)\n",
      "('спорткомплекс лужники', 3.5)\n",
      "('лужники', 1.5)\n",
      "('идти', 1.0)\n",
      "('день', 1.0)\n",
      "('бесплатный', 1.0)\n",
      "('турист', 1.0)\n",
      "('сравнение', 1.0)\n",
      "('автомобиль', 1.0)\n",
      "('каждый', 1.0)\n",
      "('сноуборд', 1.0)\n",
      "('11 00', 0)\n",
      "('21 00', 0)\n",
      "\n",
      "\n",
      "court\n",
      "('внесение изменение', 4.0)\n",
      "('аминьевский шоссе', 4.0)\n",
      "('чертановский строительство', 4.0)\n",
      "('апелляционный', 1.0)\n",
      "('москва', 1.0)\n",
      "('жалоба', 1.0)\n",
      "('представление', 1.0)\n",
      "('соответствие', 1.0)\n",
      "('связь', 1.0)\n",
      "('расположить', 1.0)\n",
      "('можайский', 1.0)\n",
      "('также', 1.0)\n",
      "('доступный', 1.0)\n",
      "('2020 год', 1.0)\n",
      "('измайловский', 1.0)\n",
      "('финансироваться', 1.0)\n",
      "('2012', 0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ake_txt = {}\n",
    "\n",
    "for key in new_txt.keys():\n",
    "    print(key)\n",
    "    rake_keys_list = rake.run(new_txt[key], maxWords=2, minFrequency=1)\n",
    "    keys_ = []\n",
    "    for k in rake_keys_list:\n",
    "        print(k)\n",
    "        keys_.append(k[0])\n",
    "    rake_txt[key] = keys_\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "['туризм', 'ярмарка', 'ресторан', 'кафе', 'гид']\n",
      "['редакция гид', 'китайский язык', 'поддержка комитет', 'иностранный язык', 'сборник попасть', 'сборник', 'путеводитель', 'русский', 'английский', 'войти', 'сервис']\n",
      "accuracy:  0.0\n",
      "precision:  0.0\n",
      "f1:  0.0\n",
      "\n",
      "\n",
      "train\n",
      "['мцд', 'тариф', 'билет', 'турникет', 'проезд']\n",
      "['тройка стрелка', 'это сообщить', 'карта движение', 'первое диаметр', 'станция марк', 'который поездка', 'это пересадка', 'оплата проезд', 'остафьево проезд', 'проезд оплачиваться', 'сутки ожидаться', 'год тариф', 'проезд', 'сутки', 'год', 'сегодня', 'валидатор', 'понедельник', '25 ноябрь', 'мцд 1', 'миллион', 'совершить', 'второе', 'пассажиропоток', 'связь', 'мцд', 'сетунь', 'мцд 2', 'метро', 'предел', 'мцк', '10', '11']\n",
      "accuracy:  0.05555555555555555\n",
      "precision:  0.4\n",
      "f1:  0.10526315789473685\n",
      "\n",
      "\n",
      "cable_car\n",
      "['праздник', 'акция', 'лужники', 'канатная дорога', 'день рождения']\n",
      "['канатный дорога', 'весь желающий', 'воробьев гора', 'удобный возможность', 'пять минута', 'велосипед лыжа', 'инвалидный коляска', 'спорткомплекс лужники', 'лужники', 'идти', 'день', 'бесплатный', 'турист', 'сравнение', 'автомобиль', 'каждый', 'сноуборд', '11 00', '21 00']\n",
      "accuracy:  0.043478260869565216\n",
      "precision:  0.2\n",
      "f1:  0.08333333333333333\n",
      "\n",
      "\n",
      "court\n",
      "['Сергей Собянин', 'апелляционный суд', 'кассационный суд', 'судебный акт', 'суд']\n",
      "['внесение изменение', 'аминьевский шоссе', 'чертановский строительство', 'апелляционный', 'москва', 'жалоба', 'представление', 'соответствие', 'связь', 'расположить', 'можайский', 'также', 'доступный', '2020 год', 'измайловский', 'финансироваться', '2012']\n",
      "accuracy:  0.0\n",
      "precision:  0.0\n",
      "f1:  0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in keys.items():\n",
    "    print(k)\n",
    "    keys_real = keys[k]\n",
    "    print (keys_real)\n",
    "    my_keys = rake_txt[k]\n",
    "    print (my_keys)\n",
    "    pred = keys_real\n",
    "    real = my_keys\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for p in pred:\n",
    "        if p in real:\n",
    "            tp += 1\n",
    "        if p not in real:\n",
    "            fp += 1\n",
    "    for i in real:\n",
    "        if i not in pred:\n",
    "            fn += 1\n",
    "    accuracy = tp / (tp + fn + fp)\n",
    "    print('accuracy: ', accuracy)\n",
    "    precision = tp / (tp + fp)\n",
    "    print('precision: ', precision)\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0    \n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0.0\n",
    "    print('f1: ', f1)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С RAKE как-то вышло слабо, но результат тем не менее есть. Он хорошо выделил ключевые словосочетания и слова, по ним действительно можно понять о чем текст. Но все словосочетания никак не совспадают с заранее выделенными ключевыми словами, совпадения только у выделенных RAKEом слов, и то совсем у небольшого количества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "ресторан 0.22023828851792784\n",
      "гид 0.2137077768574432\n",
      "заведение столица 0.20524204491381853\n",
      "издание 0.2038979419676054\n",
      "ресторанныи 0.1874563370088292\n",
      "\n",
      "\n",
      "train\n",
      "мцд 0.4463949642279051\n",
      "станция 0.21673025800480625\n",
      "это 0.19837396638301416\n",
      "миллион 0.19440575437152344\n",
      "проезд 0.19418597260437276\n",
      "\n",
      "\n",
      "cable_car\n",
      "для 0.3697738868221354\n",
      "новыи 0.1983960711642825\n",
      "канатныи дорога 0.17688651564207897\n",
      "лужники 0.1551839094382837\n",
      "минута 0.14794253321944487\n",
      "\n",
      "\n",
      "court\n",
      "строительство 0.23634906298475725\n",
      "судно 0.22776385308309677\n",
      "здание 0.22398178475367836\n",
      "год 0.20088151666988502\n",
      "кассационныи суд 0.1907985063696922\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank_txt = {}\n",
    "\n",
    "for key in new_txt.keys():\n",
    "    print(key)\n",
    "    textrank = kw(new_txt[key], pos_filter=[], scores=True)\n",
    "    keys_ = []\n",
    "    for k in textrank[:5]:\n",
    "        keys_.append(k[0])\n",
    "        print(k[0], k[1])\n",
    "    textrank_txt[key] = keys_\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "['туризм', 'ярмарка', 'ресторан', 'кафе', 'гид']\n",
      "['ресторан', 'гид', 'заведение столица', 'издание', 'ресторанныи']\n",
      "accuracy:  0.25\n",
      "precision:  0.4\n",
      "f1:  0.4000000000000001\n",
      "\n",
      "\n",
      "train\n",
      "['мцд', 'тариф', 'билет', 'турникет', 'проезд']\n",
      "['мцд', 'станция', 'это', 'миллион', 'проезд']\n",
      "accuracy:  0.25\n",
      "precision:  0.4\n",
      "f1:  0.4000000000000001\n",
      "\n",
      "\n",
      "cable_car\n",
      "['праздник', 'акция', 'лужники', 'канатная дорога', 'день рождения']\n",
      "['для', 'новыи', 'канатныи дорога', 'лужники', 'минута']\n",
      "accuracy:  0.1111111111111111\n",
      "precision:  0.2\n",
      "f1:  0.20000000000000004\n",
      "\n",
      "\n",
      "court\n",
      "['Сергеи Собянин', 'апелляционныи суд', 'кассационныи суд', 'судебныи акт', 'суд']\n",
      "['строительство', 'судно', 'здание', 'год', 'кассационныи суд']\n",
      "accuracy:  0.1111111111111111\n",
      "precision:  0.2\n",
      "f1:  0.20000000000000004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in keys.items():\n",
    "    print(k)\n",
    "    keys_real = []\n",
    "    for w in keys[k]:\n",
    "        if 'й' in w:\n",
    "            w = w.replace('й', 'и')\n",
    "        keys_real.append(w)\n",
    "    print (keys_real)\n",
    "    my_keys = textrank_txt[k]\n",
    "    print (my_keys)\n",
    "    pred = keys_real\n",
    "    real = my_keys\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for p in pred:\n",
    "        if p in real:\n",
    "            tp += 1\n",
    "        if p not in real:\n",
    "            fp += 1\n",
    "    for i in real:\n",
    "        if i not in pred:\n",
    "            fn += 1\n",
    "    accuracy = tp / (tp + fn + fp)\n",
    "    print('accuracy: ', accuracy)\n",
    "    precision = tp / (tp + fp)\n",
    "    print('precision: ', precision)\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0    \n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0.0\n",
    "    print('f1: ', f1)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У Textrank дела обстоят заметно лучше. Он уже орудует больше словами, чем словосочетаниями, а способность понять о чем был текст по выделенным словам не утрачивает. Здесь и метрики лучше сработали. У текстов про кафе и поезда лучше всего. Далее тексты про канатную дорогу и про суды. Занятно, что у Textrank куда-то делась буква 'й'. Вместо нее он встявляет в слова 'и'. Для этого я тоже немного отредактировала свои слова, чтобы метрики были получше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(new_txt.values())\n",
    "cv=CountVectorizer(max_features=10000)\n",
    "word_count_vector=cv.fit_transform(corpus)\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tf_idf_vector=tfidf_transformer.fit_transform(word_count_vector)\n",
    "df = pd.DataFrame(tf_idf_vector.toarray(), columns=cv.get_feature_names(), index=txt.keys())\n",
    "stop = set(stop)\n",
    "words = set(df.columns)\n",
    "stop_words = stop.intersection(words)\n",
    "for w in stop_words:\n",
    "    df = df.drop([w], axis=1)\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "заведение    0.321130\n",
      "столица      0.253182\n",
      "гид          0.240847\n",
      "ресторан     0.240847\n",
      "язык         0.189887\n",
      "Name: cafe, dtype: float64\n",
      "\n",
      "\n",
      "train\n",
      "мцд        0.596835\n",
      "поездка    0.210648\n",
      "рубль      0.175540\n",
      "миллион    0.166077\n",
      "проезд     0.166077\n",
      "Name: train, dtype: float64\n",
      "\n",
      "\n",
      "cable_car\n",
      "воробьев    0.240069\n",
      "гора        0.240069\n",
      "канатный    0.240069\n",
      "лужники     0.240069\n",
      "дорога      0.236592\n",
      "Name: cable_car, dtype: float64\n",
      "\n",
      "\n",
      "court\n",
      "судно            0.357545\n",
      "суд              0.321791\n",
      "строительство    0.250282\n",
      "апелляционный    0.214527\n",
      "здание           0.214527\n",
      "Name: court, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_txt = {}\n",
    "\n",
    "names = list(df.columns)\n",
    "for c in names:\n",
    "    k = df.nlargest(5, c)\n",
    "    k = k[c]\n",
    "    print(c)\n",
    "    print(k)\n",
    "    tfidf_txt[c] = list(k.index)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe\n",
      "['туризм', 'ярмарка', 'ресторан', 'кафе', 'гид']\n",
      "['заведение', 'столица', 'гид', 'ресторан', 'язык']\n",
      "accuracy:  0.25\n",
      "precision:  0.4\n",
      "f1:  0.4000000000000001\n",
      "\n",
      "\n",
      "train\n",
      "['мцд', 'тариф', 'билет', 'турникет', 'проезд']\n",
      "['мцд', 'поездка', 'рубль', 'миллион', 'проезд']\n",
      "accuracy:  0.25\n",
      "precision:  0.4\n",
      "f1:  0.4000000000000001\n",
      "\n",
      "\n",
      "cable_car\n",
      "['праздник', 'акция', 'лужники', 'канатная дорога', 'день рождения']\n",
      "['воробьев', 'гора', 'канатный', 'лужники', 'дорога']\n",
      "accuracy:  0.1111111111111111\n",
      "precision:  0.2\n",
      "f1:  0.20000000000000004\n",
      "\n",
      "\n",
      "court\n",
      "['Сергей Собянин', 'апелляционный суд', 'кассационный суд', 'судебный акт', 'суд']\n",
      "['судно', 'суд', 'строительство', 'апелляционный', 'здание']\n",
      "accuracy:  0.1111111111111111\n",
      "precision:  0.2\n",
      "f1:  0.20000000000000004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in keys.items():\n",
    "    print(k)\n",
    "    keys_real = keys[k]\n",
    "    print (keys_real)\n",
    "    my_keys = tfidf_txt[k]\n",
    "    print (my_keys)\n",
    "    pred = keys_real\n",
    "    real = my_keys\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for p in pred:\n",
    "        if p in real:\n",
    "            tp += 1\n",
    "        if p not in real:\n",
    "            fp += 1\n",
    "    for i in real:\n",
    "        if i not in pred:\n",
    "            fn += 1\n",
    "    accuracy = tp / (tp + fn + fp)\n",
    "    print('accuracy: ', accuracy)\n",
    "    precision = tp / (tp + fp)\n",
    "    print('precision: ', precision)\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0    \n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0.0\n",
    "    print('f1: ', f1)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У TF-IDF ситуация еще лучше, чем у двух предыдущих методов. По выделенным словам все так же можно понять о чем был текст. Метрики здесь показывают лучшие значения по сравнению с другими методами (но плохие, если смотреть на числа). Лидеры — тексты про кафе и поезда. Два остальных текста показывают меньшие значения по метрикам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем представить полученные результаты для разных методов и текстов одной таблице, где 4 балла -- лучший результат, 1 -- худший."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| Cafe  | Train | Cable car | Court |\n",
    "|-------------| ------------- | ------------- | ------------- | ------------- |\n",
    "| Ключевые слова | 2 | 4 | 1 | 3 |\n",
    "| RAKE | 0 | 2 | 1 | 0 |\n",
    "| Textrank | 4 | 4 | 2 | 2 |\n",
    "| TF-IDF | 4 | 4 | 2 | 2 |\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "| Итог | 10 | 14 | 8 | 7 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы Textrank и TF-IDF оказались хороши. RAKE выделяет словосочетания, для нашей цели это оказалась отнюдь не преимуществом. По результатам подсчетов победу одержал текст про поезда.  \n",
    "Из очевидных трудностей могу назвать такой кейс: канатная дорога после лемматизации становится \"канатный дорога\". В таком виде она уже не сможет ни с чем совпасть. Также выделение словосочетаний как ключевых слов не лучшая идея. Самое ходовое решение -- существительное в единственном числе (в крайнем случае можно прилагательное)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
